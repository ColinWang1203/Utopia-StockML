from Utopia_tools import *

import matplotlib.pyplot as plt
import numpy as np
import random
from sklearn import datasets, linear_model
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.linear_model import LogisticRegression
from sklearn.neural_network import MLPRegressor
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVR
from sklearn import linear_model
from sklearn.linear_model import TweedieRegressor
from sklearn.neighbors import KNeighborsRegressor
from sklearn.tree import DecisionTreeRegressor
# P_enable_logging()

All_data = [
[78, 306, 12, 396, -1.0, 28, 64.4, 37.4]
,[101, 262, 19, 382, 15.5, -57, 280.2, 31.0]
,[59, 349, 10, 418, -3.6, -90, 28.4, 29.8]
,[58, 351, 6, 415, -3.6, -96, 33.6, 26.1]
,[147, 245, 2, 394, -5.8, 64, 206.1, 23.9]
,[122, 270, 3, 395, -5.8, 28, 122.3, 23.1]
,[92, 320, 7, 419, -3.6, -90, 25.4, 22.7]
,[49, 175, 155, 379, 33.5, 4, 13.2, 22.7]
,[149, 243, 0, 392, -5.8, 64, 129.8, 21.4]
,[38, 356, 18, 412, -3.6, -90, 33.6, 21.1]
,[59, 308, 14, 381, 15.5, -11, 108.1, 20.9]
,[174, 217, 1, 392, -5.8, 28, 162.4, 20.6]
,[73, 310, 18, 401, -46.4, -29, 245.6, 20.2]
,[103, 267, 11, 381, 15.5, -57, 211.9, 20.0]
,[20, 376, 24, 420, 1.2, -53, 453.7, 18.8]
,[101, 311, 9, 421, -3.6, -90, 23.2, 18.8]
,[58, 295, 20, 373, 15.5, -11, 138.6, 15.7]
,[115, 330, 1, 446, 26.7, -24, 14.8, 14.9]
,[81, 314, 7, 402, 3.0, -32, 44.3, 14.6]
,[31, 311, 62, 404, 1.2, -53, 463.9, 12.7]
,[99, 275, 10, 384, 15.5, -11, 102.7, 12.4]
,[46, 360, 2, 408, 100, -1, 12.9, 12.0]
,[52, 346, 20, 418, 15.8, 233, 15.6, 11.4]
,[35, 346, 1, 382, -46.4, -68, 117.8, 11.3]
,[49, 333, 0, 382, -46.4, -68, 98.9, 11.2]
,[43, 350, 10, 403, 89.4, -51, 352.3, 10.8]
,[41, 366, 12, 419, 15.8, 218, 17.3, 10.3]
,[30, 351, 3, 384, -46.4, -68, 163.9, 9.6]
,[28, 258, 138, 424, 15.8, 218, 21.5, 9.3]
,[65, 336, 11, 412, 11.9, -69, 164.5, 9.2]
,[37, 329, 31, 396, 89.4, -51, 415.7, 8.9]
,[24, 371, 28, 423, 1.2, -53, 399.6, 8.7]
,[58, 315, 12, 385, 33.5, -2, 25.2, 8.7]
,[58, 315, 7, 380, -48.3, -72, 78.7, 8.6]
,[92, 273, 17, 382, 15.5, -57, 85.6, 7.9]
,[4, 428, 0, 432, -5.6, 300, 15.4, 7.8]
,[65, 363, 0, 428, -1.3, 55, 1.6, 7.4]
,[73, 332, 4, 409, 89.4, -51, 228.4, 7.3]
,[5, 428, 0, 433, -5.6, 300, 13.6, 7.2]
,[60, 352, 16, 428, 15.8, 217, 21.2, 6.9]
,[74, 348, 0, 422, -2.6, 206, 42.7, 6.8]
,[55, 346, 4, 405, 89.4, -51, 274.5, 6.6]
,[15, 400, 3, 418, -21.9, 12, 2.9, 6.4]
,[21, 351, 10, 382, -12.7, 10, 9.7, 6.4]
,[26, 290, 109, 425, 11.3, 138, 7.7, 6.3]
,[78, 326, 11, 415, -10.7, 12, 158.7, 6.2]
,[33, 384, 0, 417, -5.7, 1, 1.0, 6.1]
,[42, 355, 13, 410, 100, -1, 12.8, 6.0]
,[109, 280, 2, 391, -5.8, 64, 503.7, 5.7]
,[60, 339, 3, 402, -7.2, 31, 12.1, 5.6]
,[194, 230, 7, 431, 3.7, 77, 236.6, 5.2]
,[67, 305, 13, 385, 15.5, -2, 826.2, 5.1]
,[98, 291, 3, 392, -3.9, -34, 54.0, 5.0]
,[2, 414, 15, 431, -4.1, 320, 2.8, 4.9]
,[29, 391, 0, 420, -1.3, 107, 3.9, 4.9]
,[46, 327, 13, 386, 11.7, 67, 20.0, 4.9]
,[166, 274, 0, 440, -2.6, 206, 37.5, 4.8]
,[58, 363, 7, 428, 15.8, 217, 20.4, 4.8]
,[38, 108, 301, 445, -7.7, 15, 5.2, 4.4]
,[30, 384, 1, 415, -21.9, 12, 2.3, 4.2]
,[66, 320, 4, 390, -3.9, -34, 43.0, 4.0]
,[1, 163, 265, 429, -4.1, 186, 1.6, 3.8]
,[31, 317, 98, 446, -25.2, 24, 13.5, 3.7]
,[29, 266, 87, 382, 21.6, 224, 3.3, 3.6]
,[3, 430, 0, 433, -5.6, 733, 15.9, 3.5]
,[11, 427, 0, 438, 3.4, -29, 1.2, 3.5]
,[90, 314, 6, 410, -3.6, -71, 34.7, 3.5]
,[101, 285, 18, 404, -46.4, -29, 101.3, 3.4]
,[2, 435, 0, 437, -4.1, 320, 1.3, 3.2]
,[2, 431, 2, 435, -4.1, 320, 2.6, 3.1]
,[79, 321, 8, 408, 11.9, -69, 102.6, 3.1]
,[52, 297, 28, 376, 15.5, -11, 144.3, 3.1]
,[43, 347, 34, 424, 14.0, -5, 24.5, 2.7]
,[10, 349, 27, 386, -12.7, 50, 10.3, 2.4]
,[18, 400, 11, 429, -24.8, 34, 16.6, 2.3]
,[118, 315, 0, 433, -2.6, 206, 41.2, 2.3]
,[46, 323, 35, 404, -22.5, 58, 15.6, 2.3]
,[7, 66, 338, 410, -9.8, 53, 4.8, 2.0]
,[89, 303, 1, 393, -3.9, -34, 67.9, 1.9]
,[26, 74, 342, 441, -12.6, 18, 4.0, 1.8]
,[6, 244, 145, 395, -26.2, 33, 7.5, 1.6]
,[16, 412, 4, 432, 1.0, 86, 1.7, 1.5]
,[50, 320, 10, 380, 15.5, -2, 657.1, 1.5]
,[90, 310, 6, 406, 3.0, -32, 37.8, 1.4]
,[2, 435, 1, 438, -4.1, 320, 1.3, 1.2]
,[72, 320, 36, 427, -17.0, -7, 34.4, 1.2]
,[25, 381, 15, 421, -6.9, -43, 5.2, 1.1]
,[31, 131, 241, 402, 1.2, -68, 212.3, 1.1]
,[41, 314, 31, 386, -21.4, 6, 35.9, 1.0]
,[12, 293, 92, 397, 3.7, 118, 5.3, 0.8]
,[25, 398, 3, 426, 8.7, 36, 4.4, 0.7]
,[174, 253, 9, 436, 3.7, 77, 471.2, 0.7]
,[22, 409, 15, 446, -18.3, 310, 17.0, 0.6]
,[125, 320, 0, 445, -2.6, 40, 30.6, 0.6]
,[33, 285, 81, 399, 1.2, -68, 247.1, 0.5]
,[47, 318, 31, 396, -46.4, -20, 181.1, 0.3]
,[114, 319, 0, 433, -25.8, -15, 1.3, 0.2]
,[77, 295, 16, 388, 33.5, 18, 30.0, 0.2]
,[106, 320, 0, 426, 9.8, 64, 1.4, -0.2]
,[31, 384, 1, 416, -21.9, 12, 4.3, -0.2]
,[91, 298, 1, 390, 100, 11, 38.3, -0.3]
,[71, 327, 4, 402, 100, -1, 14.5, -0.4]
,[47, 386, 0, 433, -25.8, -15, 1.4, -0.5]
,[17, 406, 3, 426, -12.0, -13, 3.8, -0.6]
,[72, 315, 8, 395, 3.6, 1, 15.4, -0.6]
,[128, 258, 0, 386, 17.2, 51, 11.9, -0.7]
,[6, 431, 0, 437, -5.6, 733, 16.6, -1.0]
,[61, 314, 17, 392, 33.5, 18, 36.8, -1.0]
,[12, 340, 38, 390, -12.7, 50, 11.1, -1.0]
,[33, 325, 25, 383, -21.4, 44, 39.3, -1.5]
,[54, 327, 50, 431, -40.0, -20, 40.8, -1.5]
,[49, 313, 16, 378, -48.3, -72, 56.4, -1.8]
,[2, 27, 387, 416, 80.8, 152, 2.1, -1.9]
,[136, 254, 2, 392, -5.8, 64, 188.7, -2.0]
,[43, 288, 49, 380, 18.0, 90, 9.8, -2.0]
,[72, 323, 8, 403, -18.6, 173, 21.0, -2.0]
,[2, 430, 1, 433, -4.1, 424, 2.6, -2.1]
,[49, 324, 11, 384, 4.0, -4, 46.7, -2.1]
,[89, 319, 9, 417, -3.6, -96, 26.5, -2.1]
,[12, 422, 0, 434, 9.3, -9, 1.1, -2.2]
,[10, 431, 0, 441, 100, -12, 1.1, -2.3]
,[84, 300, 2, 386, -1.4, 13, 16.6, -2.3]
,[42, 362, 3, 407, -46.4, -45, 230.1, -2.3]
,[85, 359, 0, 444, -2.6, 40, 34.0, -2.4]
,[55, 366, 0, 421, -21.9, 1, 5.1, -2.5]
,[68, 310, 11, 389, 33.5, 18, 45.4, -2.5]
,[49, 360, 20, 429, 29.6, 49, 3.7, -2.6]
,[34, 309, 87, 430, 29.6, 49, 3.8, -2.8]
,[52, 309, 16, 377, 31.5, 114, 5.5, -2.8]
,[18, 409, 0, 427, -21.4, 44, 2.1, -2.9]
,[35, 386, 3, 424, -16.1, -11, 4.8, -3.4]
,[30, 176, 241, 447, -7.7, 14, 5.6, -3.6]
,[42, 308, 25, 375, 17.1, 87, 12.6, -3.7]
,[19, 333, 78, 430, -13.3, 26, 2.7, -4.0]
,[28, 405, 13, 446, -18.3, 310, 16.4, -4.1]
,[73, 325, 30, 428, 11.9, 36, 751.2, -4.2]
,[1, 16, 399, 416, -4.1, 186, 3.4, -4.3]
,[4, 24, 392, 419, 80.8, 45, 1.7, -4.4]
,[60, 315, 9, 384, 14.5, 18, 77.0, -4.6]
,[53, 327, 6, 386, 0.4, 392, 91.0, -4.7]
,[54, 327, 4, 385, -18.2, -11, 69.7, -5.0]
,[42, 136, 223, 400, -4.9, -54, 13.4, -5.1]
,[134, 281, 8, 423, 2.7, 44, 24.2, -5.1]
,[3, 40, 377, 420, 80.8, 152, 2.0, -5.3]
,[36, 380, 5, 421, 2.3, -20, 34.7, -5.4]
,[10, 126, 256, 392, 4.0, 11, 55.6, -5.5]
,[67, 304, 9, 380, 100, 5, 52.9, -5.5]
,[43, 346, 12, 401, -1.6, -10, 28.2, -5.7]
,[78, 325, 26, 429, -10.2, -39, 118.0, -6.4]
,[8, 426, 0, 434, -5.6, 733, 7.9, -6.8]
,[96, 297, 5, 398, 100, 41, 23.9, -7.1]
,[64, 319, 1, 384, 14.5, 18, 48.7, -7.2]
,[82, 305, 0, 387, -3.4, 243, 419.0, -7.7]
,[52, 334, 22, 408, -46.4, -29, 358.5, -7.7]
,[28, 293, 101, 422, 7.5, -13, 8.7, -7.8]
,[23, 403, 1, 427, 34.4, 108, 3.6, -8.1]
,[158, 270, 7, 435, 3.7, 77, 350.3, -8.2]
,[29, 303, 75, 407, 4.0, 11, 76.6, -8.5]
,[44, 377, 3, 424, 2.3, -20, 46.0, -8.7]
,[69, 326, 10, 405, -46.4, -29, 343.9, -8.9]
,[54, 353, 23, 430, -40.0, -20, 37.6, -9.0]
,[166, 288, 0, 454, 3.7, 51, 34.4, -9.8]
,[42, 343, 40, 425, 55.7, 142, 17.6, -10.5]
,[40, 332, 31, 403, -1.6, -10, 37.7, -10.8]
,[106, 282, 37, 425, -10.2, -39, 93.4, -10.9]
,[13, 193, 189, 395, 4.0, 11, 68.4, -13.2]
,[50, 321, 16, 387, -3.4, 243, 531.3, -14.5]
,[18, 102, 284, 403, 11.8, -29, 3.8, -14.6]
,[174, 251, 6, 431, -1.0, 29, 72.7, -15.0]
,[32, 309, 57, 398, 1.2, -68, 172.9, -16.0]
,[20, 197, 189, 406, 21.9, 68, 4.0, -17.3]
,[118, 330, 1, 449, 3.7, 51, 21.8, -22.5]
]


# remove this afterward
# All_data = [[a for a in b[0:7]] for b in All_data]
# with open('model_random_forest.pickle', 'rb') as f:
#     model = pickle.load(f)

x = [ a[0:7] for a in All_data]
y = [ a[7] for a in All_data]
x, y = np.array(x), np.array(y)



model = RandomForestRegressor(n_estimators=500,criterion='mae',ccp_alpha=0.1)



model.fit(x,y)

guess_error = 0
guess_low_range = np.median(y)-np.mean(y)/2
guess_high_range = np.median(y)+np.mean(y)/2
# print(guess_low_range)
# print(guess_high_range)
for dy in y:
    guess_result = random.uniform(guess_low_range,guess_high_range)
    guess_error += abs(guess_result - dy)
    # print(guess_result)
    # print(guess_error)
Guess_error_avg = guess_error / len(y)
print('TR Guess_error_avg = '+str(Guess_error_avg))

# show the training error
error_sum = 0 
for dx,dy in zip(x,y):
    diff = abs(model.predict([dx])[0] - dy)
    print(model.predict([dx])[0])
    print('diff = '+str(diff))
    error_sum += diff
TR_error = error_sum/len(x)
print('Training error is : '+str(TR_error))
print('Training score is :'+str(model.score(x,y)))

#=====================

Test_data = [
[53, 297, 17, 367, -27.6, 21, 62.5, 10.5]
,[128, 253, 6, 387, 9.0, -79, 0.3, 8.1]
,[62, 302, 2, 366, -4.0, -54, 0.9, 4.5]
,[54, 297, 14, 365, -17.2, -39, 0.7, 4.5]
,[62, 300, 75, 437, -4.4, 117, 3.6, 3.4]
,[137, 229, 14, 380, -9.3, -35, 0.4, 2.9]
,[56, 309, 8, 373, 24.4, -81, 1.4, 2.5]
,[107, 309, 11, 427, -21.7, -50, 0.5, 2.3]
,[26, 245, 93, 364, -13.3, -2, 0.9, 2.0]
,[87, 265, 25, 377, 1.8, -56, 1.1, 1.9]
,[97, 284, 6, 387, -20.1, -26, 0.9, 1.9]
,[101, 287, 6, 394, 9.0, -79, 0.3, 1.7]
,[71, 297, 66, 434, -17.0, 133, 3.1, 1.6]
,[121, 245, 18, 384, -9.3, -35, 0.5, 1.4]
,[35, 297, 36, 368, -13.3, -2, 0.9, 1.3]
,[108, 272, 7, 387, -0.6, -26, 3.5, 1.1]
,[130, 284, 9, 423, 10.1, -52, 0.6, 0.8]
,[150, 232, 4, 386, 28.1, -59, 1.4, 0.5]
,[37, 260, 63, 360, -7.4, -1, 0.9, 0.1]
,[130, 225, 13, 368, 1.8, -56, 1.0, 0.0]
,[112, 250, 7, 369, -4.0, -56, 1.0, 0.0]
,[145, 216, 16, 376, 1.8, -56, 1.0, -0.6]
,[126, 285, 4, 415, 10.1, -52, 0.6, -0.8]
,[125, 289, 6, 419, 10.1, -52, 0.6, -0.9]
,[100, 282, 4, 386, 31.4, -26, 0.6, -1.0]
,[55, 307, 8, 370, -9.4, -27, 0.4, -1.3]
,[23, 281, 61, 365, -13.4, 3, 1.0, -1.5]
,[140, 241, 4, 385, 28.1, -59, 1.5, -1.7]
,[122, 282, 2, 406, 9.0, -79, 0.2, -1.8]
,[140, 214, 22, 376, 1.8, -56, 1.1, -1.9]
,[68, 296, 2, 366, -7.3, -43, 0.6, -2.0]
,[109, 285, 37, 431, -21.7, -50, 0.6, -2.0]
,[53, 316, 4, 373, -9.4, -27, 0.4, -2.5]
,[57, 306, 5, 368, -27.6, 21, 59.3, -3.0]
,[49, 304, 10, 363, -17.2, -39, 0.7, -3.1]
,[106, 282, 44, 432, 24.7, -82, 0.3, -5.0]
,[166, 246, 3, 415, 9.0, -85, 0.3, -5.4]
,[45, 323, 6, 374, 26.8, -48, 0.2, -5.6]
,[114, 280, 39, 433, 24.7, -82, 0.2, -5.7]
,[49, 309, 5, 363, -17.2, -22, 1.4, -6.6]
,[43, 324, 6, 373, 26.8, -48, 0.2, -7.6]
]

x = [ a[0:7] for a in Test_data]
y = [ a[7] for a in Test_data]
x, y = np.array(x), np.array(y)
guess_error = 0
guess_low_range = np.median(y)-np.mean(y)/2
guess_high_range = np.median(y)+np.mean(y)/2
# print(guess_low_range)
# print(guess_high_range)
for dy in y:
    guess_result = random.uniform(guess_low_range,guess_high_range)
    guess_error += abs(guess_result - dy)
    # print(guess_result)
    # print(guess_error)
Guess_error_avg = guess_error / len(y)
print('VA Guess_error_avg = '+str(Guess_error_avg))

# show the training error
error_sum = 0 
for dx,dy in zip(x,y):
    diff = abs(model.predict([dx])[0] - dy)
    # print(model.predict([dx])[0])
    # print('diff = '+str(diff))
    error_sum += diff
TR_error = error_sum/len(x)
print('VA error is : '+str(TR_error))

P()






# All_data = [[a for a in b[0:8]]+[a for a in b[8:]] for b in All_data]

# print(All_data)

# CHECK MODEL IF NORMAL


# t = [[0.1,0.2],[0.3,0.4],[0.3,0.6],[0.2,0.5],[0.06,0.07],[0.12,0.05]]
# m = [0.3,0.7,0.9,0.7,0.14,0.17]
# # scalar1 = StandardScaler()
# # scalar1.fit(t)
# # t = scalar1.transform(t)
# # scalar2 = StandardScaler()
# # scalar2.fit(m)
# # m = scalar2.transform(m)
# # print(t)
# # print(m)


# # model = RandomForestRegressor(n_estimators=1000, oob_score=True, random_state=1000)
# # model = LogisticRegression(C=1000.0, random_state=0)
# # model = SVR(kernel='poly', C=100, gamma='auto', degree=3, epsilon=.1,
# #                coef0=1)
# model = MLPRegressor(hidden_layer_sizes=(10), activation="relu",
#                  solver='lbfgs', alpha=0.001,
#                  batch_size='auto', learning_rate="constant",
#                  learning_rate_init=0.01,
#                  power_t=0.5, max_iter=2000,tol=1e-4)
# model.fit(t, m)
# # tt = [[2,3],[4,5]]
# # mm = [5,9]
# # tt = scalar1.transform([[0.3,0.4]])
# # mm = model.predict(tt)
# # mm = scalar2.inverse_transform(mm)
# # print(tt)
# # print(mm)
# # print(model.score(tt,mm))
# tt = [[0.2,0.3],[0.4,0.5]]
# mm = [0.5,0.9]
# print(model.score(tt,mm))
# print(model.predict([[0.3,0.55]]))

# MAIN

np.random.shuffle(All_data)

x = [ a[0:7] for a in All_data[:(len(All_data)-20)]]
y = [ a[7] for a in All_data[:(len(All_data)-20)]]

x, y = np.array(x), np.array(y)
print('Median is '+str(np.median(y)))
model_ori = RandomForestRegressor()

model_ori.fit(x, y)
with open('model_random_forest.pickle', 'wb') as f:
    pickle.dump(model_ori, f)
with open('model_random_forest.pickle', 'rb') as f:
    model = pickle.load(f)
r_sq = model.score(x, y)
result = []
result_guess = []
guess_data = [ a[7] for a in All_data[-20:]]
# print(guess_data)
# print(np.median(guess_data))
# print(np.mean(guess_data))
guess_low_range = np.median(guess_data)-np.mean(guess_data)/2
guess_high_range = np.median(guess_data)+np.mean(guess_data)/2
print(guess_low_range)
print(guess_high_range)

for i in range(1,20):
    # print('-----------------')
    x =  [All_data[-i][0:7]]
    y = All_data[-i][7]
    y_pred = model.predict(x)
    y_guess = random.uniform(guess_low_range,guess_high_range)
    result.append(abs(y_pred - y))
    result_guess.append(abs(y_guess - y))
    # print(y)
    # print(y_pred)
    # print(y_guess)

a=[ a[0:7] for a in All_data[-20:]]
b=[ a[7] for a in All_data[-20:]]
for aa,bb in zip(a,b):
    # print('input:')
    # print(aa)
    output = model.predict([aa])
    if output > 3:
        print('-----------------')
        print('answer:')
        print(bb)
        print('output:')
        print(output)
print('-----------------')
print('Guess error is '+str(sum(result_guess)/len(result_guess)))
print('Prediction error is '+str(sum(result)/len(result)))
print('Score is '+str(model.score(a,b)))

# a=[ a[0:7] for a in All_data[-3:]]
# b=[ a[7] for a in All_data[-3:]]
# print(a)
# print(b)
# today_input = a
# final = []
# for ti in today_input:
#     print(ti)
#     final.append([model.predict([ti]),ti])
# final.sort(key=lambda x: x[0], reverse=True)
# print(final)

today_input = [
[109, 285, 37, 431, -18.5, 1, 13.1]
,[109, 285, 37, 431, -29.8, 1, 6.3]
,[109, 285, 37, 431, 1.7, 1, 4.4]
,[109, 285, 37, 431, -10.7, 1, 4.1]
,[109, 285, 37, 431, 14.4, 1, 3.8]
,[109, 285, 37, 431, 36.6, 1, 3.7]
,[109, 285, 37, 431, -5.7, 1, 3.2]
,[109, 285, 37, 431, -5.6, 1, 3.0]
,[109, 285, 37, 431, 4.6, 1, 2.9]
,[109, 285, 37, 431, 41.2, 1, 2.8]
,[109, 285, 37, 431, 21.0, 1, 2.4]
,[109, 285, 37, 431, -4.4, 1, 2.4]
,[109, 285, 37, 431, -0.6, 1, 2.4]
,[109, 285, 37, 431, 8.8, 1, 2.2]
,[109, 285, 37, 431, 24.4, 1, 2.1]
,[109, 285, 37, 431, -6.6, 1, 2.1]
,[109, 285, 37, 431, 12.2, 1, 2.1]
,[109, 285, 37, 431, 12.6, 1, 2.0]
,[109, 285, 37, 431, 8.8, 1, 2.0]
,[109, 285, 37, 431, 3.3, 1, 1.9]
,[109, 285, 37, 431, -9.3, 1, 1.9]
,[109, 285, 37, 431, -8.4, 1, 1.9]
,[109, 285, 37, 431, -8.2, 1, 1.9]
,[109, 285, 37, 431, 5.7, 1, 1.9]
,[109, 285, 37, 431, 24.9, 1, 1.9]
,[109, 285, 37, 431, -13.5, 1, 1.8]
,[109, 285, 37, 431, -26.8, 1, 1.8]
,[109, 285, 37, 431, 24.9, 1, 1.8]
,[109, 285, 37, 431, -14.9, 1, 1.8]
,[109, 285, 37, 431, -16.0, 1, 1.8]
,[109, 285, 37, 431, 19.5, 1, 1.8]
,[109, 285, 37, 431, -33.4, 1, 1.8]
,[109, 285, 37, 431, -6.8, 1, 1.8]
,[109, 285, 37, 431, 1.0, 1, 1.8]
,[109, 285, 37, 431, 13.2, 1, 1.8]
,[109, 285, 37, 431, -20.0, 1, 1.7]
,[109, 285, 37, 431, -13.3, 1, 1.7]
,[109, 285, 37, 431, -3.8, 1, 1.7]
,[109, 285, 37, 431, 19.1, 1, 1.7]
,[109, 285, 37, 431, -36.7, 1, 1.6]
,[109, 285, 37, 431, -12.7, 1, 1.6]
,[109, 285, 37, 431, -10.6, 1, 1.6]
,[109, 285, 37, 431, -0.2, 1, 1.6]
,[109, 285, 37, 431, -42.4, 1, 1.6]
,[109, 285, 37, 431, 19.1, 1, 1.6]
,[109, 285, 37, 431, 3.1, 1, 1.6]
,[109, 285, 37, 431, 17.9, 1, 1.6]
,[109, 285, 37, 431, -10.3, 1, 1.6]
,[109, 285, 37, 431, 16.2, 1, 1.6]
,[109, 285, 37, 431, 19.1, 1, 1.6]
,[109, 285, 37, 431, -19.9, 1, 1.5]
,[109, 285, 37, 431, 0.3, 1, 1.5]
,[109, 285, 37, 431, -16.1, 1, 1.5]
,[109, 285, 37, 431, -1.9, 1, 1.5]
,[109, 285, 37, 431, 58.4, 1, 1.5]
,[109, 285, 37, 431, 16.0, 1, 1.5]
,[109, 285, 37, 431, 6.1, 1, 1.5]
,[109, 285, 37, 431, -5.8, 1, 1.4]
,[109, 285, 37, 431, -5.7, 1, 1.4]
,[109, 285, 37, 431, 3.7, 1, 1.4]
,[109, 285, 37, 431, -17.7, 1, 1.4]
,[109, 285, 37, 431, -18.0, 1, 1.4]
,[109, 285, 37, 431, 6.5, 1, 1.4]
,[109, 285, 37, 431, 8.4, 1, 1.4]
,[109, 285, 37, 431, 3.4, 1, 1.3]
,[109, 285, 37, 431, -4.5, 1, 1.3]
,[109, 285, 37, 431, 7.2, 1, 1.3]
,[109, 285, 37, 431, -16.2, 1, 1.3]
,[109, 285, 37, 431, -50.4, 1, 1.3]
,[109, 285, 37, 431, -20.1, 1, 1.3]
,[109, 285, 37, 431, 27.4, 1, 1.3]
,[109, 285, 37, 431, 24.7, 1, 1.3]
,[109, 285, 37, 431, -1.8, 1, 1.3]
,[109, 285, 37, 431, 10.9, 1, 1.3]
,[109, 285, 37, 431, 12.8, 1, 1.2]
,[109, 285, 37, 431, 1.4, 1, 1.2]
,[109, 285, 37, 431, -8.5, 1, 1.2]
,[109, 285, 37, 431, -2.7, 1, 1.2]
,[109, 285, 37, 431, -9.0, 1, 1.2]
,[109, 285, 37, 431, 3.7, 1, 1.2]
,[109, 285, 37, 431, 37.7, 1, 1.2]
,[109, 285, 37, 431, -14.8, 1, 1.2]
,[109, 285, 37, 431, -20.9, 1, 1.2]
,[109, 285, 37, 431, 0.3, 1, 1.2]
,[109, 285, 37, 431, -10.5, 1, 1.1]
,[109, 285, 37, 431, 2.2, 1, 1.1]
,[109, 285, 37, 431, -5.2, 1, 1.1]
,[109, 285, 37, 431, -28.9, 1, 1.1]
,[109, 285, 37, 431, 1.3, 1, 1.0]
,[109, 285, 37, 431, 16.6, 1, 1.0]
,[109, 285, 37, 431, 17.2, 1, 1.0]
,[109, 285, 37, 431, -15.6, 1, 1.0]
,[109, 285, 37, 431, 15.5, 1, 1.0]
,[109, 285, 37, 431, 31.4, 1, 0.9]
,[109, 285, 37, 431, -6.9, 1, 0.9]
,[109, 285, 37, 431, -24.5, 1, 0.9]
,[109, 285, 37, 431, 1.8, 1, 0.9]
,[109, 285, 37, 431, 3.4, 1, 0.9]
,[109, 285, 37, 431, 17.3, 1, 0.8]
,[109, 285, 37, 431, 55.7, 1, 0.8]
,[109, 285, 37, 431, 6.6, 1, 0.8]
,[109, 285, 37, 431, 3.1, 1, 0.7]
,[109, 285, 37, 431, 10.1, 1, 0.7]
,[109, 285, 37, 431, -21.7, 1, 0.6]
,[109, 285, 37, 431, -16.4, 1, 0.6]
,[109, 285, 37, 431, 55.7, 1, 0.6]
,[109, 285, 37, 431, 53.9, 1, 0.6]
,[109, 285, 37, 431, 9.8, 1, 0.6]
,[109, 285, 37, 431, 12.1, 1, 0.5]
]
final = []
for ti in today_input:
    print(ti)
    final.append([model.predict([ti]),ti])
final.sort(key=lambda x: x[0])
P_printl(final)









#  STRESS TEST

# TURE_FINAL = []
# for mm in range(1,11):
#     n_estimators_c = mm * 100
#     for nn in range(1,11):
#         random_state_c = nn * 100
#         final_result_list = []
#         for n in range(1,10):

#             np.random.shuffle(All_data)

#             x = [ a[0:7] for a in All_data[:(len(All_data)-20)]]
#             y = [ a[7] for a in All_data[:(len(All_data)-20)]]

#             x, y = np.array(x), np.array(y)
#             # P_printl(x)
#             # print(y)

#             # model = linear_model.LinearRegression().fit(x, y)
#             model = RandomForestRegressor(n_estimators=n_estimators_c, oob_score=True, random_state=random_state_c, warm_start = True)
#             model.fit(x, y)
#             r_sq = model.score(x, y)
#             # print('coefficient of determination:', r_sq)
#             # print('intercept:', model.intercept_)
#             # print('slope:', model.coef_)
#             result = []
#             result_guess = []
#             for i in range(1,20):
#                 x =  [All_data[-i][0:7]]
#                 y = All_data[-i][7]
#                 y_pred = model.predict(x)
#                 result.append(abs(y_pred - y))

#             final_result_list.append(sum(result)/len(result))


#         TURE_FINAL.append([n_estimators_c,random_state_c,(sum(final_result_list)/len(final_result_list))])
# print(TURE_FINAL)